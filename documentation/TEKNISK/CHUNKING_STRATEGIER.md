# Chunking Strategier Guide

## Oversigt

DHO Semantisk S√∏gemaskine underst√∏tter flere tekst chunking strategier til optimal behandling af forskellige dokumenttyper. Denne guide forklarer hver strategi og hvorn√•r de skal bruges.

## üß© **Chunking Koncepter**

### Hvad er Chunking?
Chunking opdeler lange dokumenter i mindre, h√•ndterbare tekststykker der kan:
- Generere meningsfulde embeddings
- Passe inden for model token limits
- Bevare kontekst og sammenh√¶ng
- Optimere s√∏geperformance

### Vigtige Parametre
- **Chunk Size**: Maksimum tokens per chunk
- **Overlap**: Delte ord mellem tilst√∏dende chunks
- **Boundary Respect**: Om chunks respekterer s√¶tnings-/afsnitsgr√¶nser
- **Title Injection**: Om bog titel tilf√∏jes til chunks

## üìù **Tilg√¶ngelige Strategier**

### 1. Sentence Splitter (Standard)

#### Konfiguration
```bash
CHUNKING_STRATEGY=sentence_splitter
CHUNK_SIZE=500  # Respekteres
```

#### Funktionalitet
- **Opdeling**: Splitter tekst ved s√¶tningsgr√¶nser
- **Token Limit**: Respekterer CHUNK_SIZE parameter
- **Titel Prefiks**: Tilf√∏jer bog titel til starten af hver chunk
- **Boundary Respect**: Ja - splitter aldrig midt i s√¶tning
- **Cross-Page**: H√•ndterer tekst p√• tv√¶rs af sider

#### Algoritme
```python
1. Udvind bog titel fra metadata
2. For hver side:
   a. Opdel tekst i s√¶tninger
   b. Kombiner s√¶tninger til chunks
   c. Tilf√∏j titel prefiks
   d. Respekt√©r max_tokens limit
3. H√•ndt√©r cross-page chunks
4. Returner titel-pr√¶fiksede chunks
```

#### Fordele
- **Bevarar sprog flow**: Chunks slutter ved naturlige pauser
- **H√∏j s√∏gekvalitet**: Titel hj√¶lper med relevans
- **Fleksibel st√∏rrelse**: Tilpasser til CHUNK_SIZE
- **God til korte/mellemlange dokumenter**

#### Ulemper
- **Variabel chunk st√∏rrelse**: Kan give uens performance
- **Titel overhead**: Bruger tokens p√• titel i hver chunk

#### Bedst til
- Generel dokumentbehandling
- S√∏gekvalitet prioriteret
- Dokumenter med god s√¶tningsstruktur
- N√•r titel kontekst er v√¶rdifuld

#### Eksempel Output
```
Input: "Dette er f√∏rste s√¶tning. Dette er anden s√¶tning. Dette er tredje s√¶tning."
Titel: "Min Test Bog"
Chunk Size: 15 tokens

Output Chunk:
"Min Test Bog: Dette er f√∏rste s√¶tning. Dette er anden s√¶tning."
```

### 2. Word Overlap

#### Konfiguration
```bash
CHUNKING_STRATEGY=word_overlap
CHUNK_SIZE=400  # Ignoreres - bruger fast st√∏rrelse
```

#### Funktionalitet
- **Opdeling**: Fast 400-ord chunks med 50-ord overlap
- **Token Limit**: Ignorerer CHUNK_SIZE parameter
- **Titel Prefiks**: Ingen - kun ren tekst
- **Overlap**: 50 ord deles mellem tilst√∏dende chunks
- **Cross-Page**: Fuld support p√• tv√¶rs af sider

#### Algoritme
```python
1. Kombiner al tekst fra alle sider
2. Opdel i individuelle ord
3. Opret 400-ord chunks med 50-ord overlap:
   - Chunk 1: ord 1-400
   - Chunk 2: ord 351-750 (overlap: 351-400)
   - Chunk 3: ord 701-1100 (overlap: 701-750)
4. Returner chunks uden titel prefiks
```

#### Fordele
- **Konsistent st√∏rrelse**: Alle chunks er samme st√∏rrelse
- **Kontekst bevarelse**: Overlap bevarer sammenh√¶ng
- **Optimal for ML**: Ensartede input til embedding models
- **Cross-page seamless**: Ingen tab ved sidegr√¶nser

#### Ulemper
- **Ignorerer CHUNK_SIZE**: Kan ikke tilpasse st√∏rrelse
- **Kan splitte midt i s√¶tning**: Mindre respekt for sprog boundaries
- **Ingen titel kontekst**: Chunks mangler bog identificering

#### Bedst til
- Lange dokumenter
- N√•r overlap er kritisk
- Machine learning training
- N√•r konsistent chunk st√∏rrelse er vigtig
- Cross-document analyse

#### Eksempel Output
```
Input: 500 ord tekst
Fast Configuration: 400 ord chunks, 50 ord overlap

Chunk 1: ord 1-400
Chunk 2: ord 351-500 (overlap med chunk 1: ord 351-400)
```

## ‚öôÔ∏è **Konfiguration og Tuning**

### Chunk Size Optimering

#### Sm√• Chunks (200-300 tokens)
```bash
CHUNK_SIZE=250
```
- **Fordele**: Pr√¶cise matches, hurtig processering
- **Ulemper**: Mangler kontekst, flere chunks per dokument
- **Bedst til**: Korte dokumenter, faktuelle sp√∏rgsm√•l

#### Medium Chunks (400-600 tokens)
```bash
CHUNK_SIZE=500
```
- **Fordele**: God balance mellem pr√¶cision og kontekst
- **Ulemper**: Moderat processering tid
- **Bedst til**: Generel brug, de fleste dokumenttyper

#### Store Chunks (700-1000 tokens)
```bash
CHUNK_SIZE=800
```
- **Fordele**: Maksimal kontekst, f√¶rre chunks
- **Ulemper**: Mindre pr√¶cise matches, l√¶ngere processering
- **Bedst til**: Komplekse dokumenter, kontekst-sensitive s√∏gninger

### Provider-Specifik Optimering

#### OpenAI Optimering
```bash
# OpenAI text-embedding-3-small: 8191 token limit
CHUNKING_STRATEGY=sentence_splitter
CHUNK_SIZE=500  # Sikker margin under limit
```

#### Ollama Optimering
```bash
# Nomic-embed-text: 2048 token limit
CHUNKING_STRATEGY=sentence_splitter
CHUNK_SIZE=400  # Sikker margin
```

### Performance Tuning

#### H√∏j Throughput
```bash
CHUNKING_STRATEGY=word_overlap  # Konsistent processering
CHUNK_SIZE=400  # Ignoreres men sat for reference
```

#### H√∏j Kvalitet
```bash
CHUNKING_STRATEGY=sentence_splitter  # Respekterer sprog struktur
CHUNK_SIZE=500  # Optimal balance
```

## üî¨ **Teknisk Implementation**

### Chunking Strategy Factory
```python
from .chunking import ChunkingStrategyFactory

# Opret strategi baseret p√• environment
strategy = ChunkingStrategyFactory.create_strategy(
    os.getenv("CHUNKING_STRATEGY", "sentence_splitter")
)
```

### Custom Strategy Development
For at tilf√∏je nye strategier:

1. **Udvid ChunkingStrategy base class**
2. **Implement√©r chunk_text metoden**
3. **Registr√©r i factory**
4. **Tilf√∏j til environment validation**

### Strategy Interface
```python
class ChunkingStrategy(ABC):
    @abstractmethod
    def chunk_text(self, text: str, max_tokens: int, title: str = "") -> List[str]:
        pass
```

## üìä **Performance Sammenligning**

| Aspekt | Sentence Splitter | Word Overlap |
|--------|------------------|--------------|
| **Konsistens** | Variabel chunk st√∏rrelse | Fast chunk st√∏rrelse |
| **Sprog Respekt** | H√∏j (s√¶tningsgr√¶nser) | Medium (kan splitte) |
| **Kontekst** | Medium (titel + chunk) | H√∏j (overlap) |
| **Cross-Page** | God | Fremragende |
| **Performance** | Medium | H√∏j |
| **S√∏gekvalitet** | H√∏j (med titel) | God (uden titel) |
| **Memory Usage** | Lavere | H√∏jere |

## üß™ **Test og Validering**

### Test Chunking Strategy
```bash
# Test med lille dokument
echo "Test bog URL" > test_input.txt

# Test sentence splitter
CHUNKING_STRATEGY=sentence_splitter ./scripts/process_books.sh --file test_input.txt

# Test word overlap
CHUNKING_STRATEGY=word_overlap ./scripts/process_books.sh --file test_input.txt

# Sammenlign resultater
```

### Debugging Chunking
```bash
# Detaljeret logging
LOG_LEVEL=DEBUG CHUNKING_STRATEGY=sentence_splitter python -c "
from create_embeddings.chunking import ChunkingStrategyFactory
strategy = ChunkingStrategyFactory.create_strategy('sentence_splitter')
chunks = strategy.chunk_text('Test tekst her.', 100, 'Test Titel')
print(f'Chunks: {chunks}')
"
```

## üöÄ **Best Practices**

### Strategi Valg Guidelines

#### V√¶lg Sentence Splitter n√•r:
- Dokumenter har god s√¶tningsstruktur
- S√∏gekvalitet er h√∏jeste prioritet
- Titel kontekst er v√¶rdifuld
- Dokumenterne er korte til mellemlange

#### V√¶lg Word Overlap n√•r:
- Dokumenter er meget lange
- Kontekst p√• tv√¶rs af chunks er kritisk
- Konsistent chunk st√∏rrelse er n√∏dvendig
- Performance er h√∏jeste prioritet

### Optimering Workflow
1. **Start med sentence_splitter** for de fleste use cases
2. **Test search kvalitet** med representative queries
3. **M√•linger performance** med din hardware
4. **Eksperiment√©r med word_overlap** hvis n√∏dvendigt
5. **Tune CHUNK_SIZE** baseret p√• resultater

---

**Se ogs√•:**
- [Konfigurationsguide](../KONFIGURATION.md) for parameter detaljer
- [Bog Processering](../BRUGERGUIDER/BOG_PROCESSERING.md) for praktisk brug
- [API Reference](API_REFERENCE.md) for teknisk implementation
