# Bog Processering Guide

## Oversigt

Denne guide viser hvordan du tilf√∏jer b√∏ger til DHO Semantisk S√∏gemaskine systemet. Du k√∏rer alt fra din **v√¶rtsmaskine terminal** - du beh√∏ver aldrig at g√• ind i ## üê≥ **Container Management**

### Hvorn√•r Skal Containers Genbygges?

**Rebuild book-processor container efter:**
- ‚úÖ √Ündringer i `create_embeddings/*.py` filer
- ‚úÖ Database interface √¶ndringer (`database/*.py`)
- ‚úÖ Dependency opdateringer (`requirements.txt`)
- ‚úÖ Chunking eller embedding provider √¶ndringer

**Rebuild IKKE n√∏dvendigt efter:**
- ‚ùå `.env` konfiguration √¶ndringer
- ‚ùå Bog liste opdateringer
- ‚ùå Docker Compose environment variabler

### Container Rebuild Procedure

```bash
# 1. Stop eksisterende containers
cd soegemaskine
docker-compose down

# 2. Genbyg book-processor med kode√¶ndringer
docker-compose build book-processor

# 3. Start alle services igen
docker-compose --profile embeddings up -d

# 4. Verific√©r at alt virker
cd ..
./scripts/process_books.sh --validate
```

### Debug Container Issues

```bash
# Tjek container status
docker-compose ps

# Se live logs
docker-compose logs -f book-processor

# Inspicer container indhold
docker exec -it dho-book-processor ls -la /app

# Tjek environment variabler i container
docker exec -it dho-book-processor printenv | grep POSTGRES
```

## üõ† **Konfiguration Troubleshooting**ocker container terminaler.

## üöÄ **Hurtig Start**

### Foruds√¶tninger
1. Docker og Docker Compose installeret
2. System konfigureret (se [Installation Guide](INSTALLATION.md))
3. Database og embedding service k√∏rende

### Grundl√¶ggende Workflow
```bash
# 1. Valid√©r konfiguration
./scripts/process_books.sh --validate

# 2. Process√©r b√∏ger
./scripts/process_books.sh --file mine_boeger.txt

# 3. Overv√•g fremgang
./scripts/process_books.sh --monitor

# 4. Genpr√∏v fejlede b√∏ger
./scripts/process_books.sh --retry
```

## üìù **Forberedelse**

### Opret Bogliste
Opret en tekstfil p√• din v√¶rtsmaskine med √©n URL per linje:

```bash
# Opret fil
nano mine_boeger.txt

# Eksempel indhold:
https://example.com/bog1.pdf
https://example.com/bog2.pdf
https://example.com/bog3.pdf
```

### Underst√∏ttede Formater
- **PDF filer**: Prim√¶rt underst√∏ttet format
- **URL krav**: Direkte links til PDF filer
- **Filst√∏rrelse**: Anbefalet under 50MB per fil

## üîß **Processering Kommandoer**

### Valid√©r Konfiguration
```bash
./scripts/process_books.sh --validate
```

**Hvad sker der:**
- Starter midlertidig Docker container
- Validerer `.env` fil konfiguration
- Tester database forbindelse
- Verificerer embedding provider
- Fjerner container efter test

**Forventet output:**
```
‚úÖ Alle p√•kr√¶vede milj√∏variabler er sat og gyldige
Udbyder: ollama
Chunking Strategy: sentence_splitter
Chunk St√∏rrelse: 500
Database forbindelse: OK
Embedding provider: OK
```

### Process√©r B√∏ger
```bash
./scripts/process_books.sh --file mine_boeger.txt
```

**Processerings flow:**
1. Starter processing container
2. L√¶ser bog URLs fra fil
3. Downloader og analyserer hver bog
4. Opdeler tekst i chunks via valgt strategi
5. Genererer embeddings via valgt provider
6. Gemmer til database
7. Genererer status rapport

### Overv√•g Fremgang
```bash
# Real-time monitoring
./scripts/process_books.sh --monitor

# Eller tjek status fil
cat output/processing_status.json
```

**Status fil eksempel:**
```json
{
  "status": "k√∏rer",
  "total_boeger": 10,
  "behandlet": 7,
  "fejlet": 1,
  "sidst_opdateret": "2025-06-30T14:30:00",
  "embedding_model": "nomic-embed-text",
  "udbyder": "ollama"
}
```

### Genpr√∏v Fejlede B√∏ger
```bash
./scripts/process_books.sh --retry
```

**Hvad sker der:**
- L√¶ser fejlede b√∏ger fra `failed/failed_books.json`
- Opretter ny bog liste med kun fejlede URLs
- Genprocesserer med samme konfiguration
- Opdaterer status og fejl statistikker

## üìä **Processing Strategier**

### Chunking Strategier

#### Sentence Splitter (Standard)
```bash
# I .env fil
CHUNKING_STRATEGY=sentence_splitter
CHUNK_SIZE=500
```

**Karakteristika:**
- Opdeler efter s√¶tninger
- Respekterer max tokens (CHUNK_SIZE)
- Tilf√∏jer bog titel til hver chunk
- Bedst til: Generel tekst s√∏gning

#### Word Overlap
```bash
# I .env fil
CHUNKING_STRATEGY=word_overlap
CHUNK_SIZE=400  # Ignoreres, bruger fast 400-ord chunks
```

**Karakteristika:**
- Fast 400-ord chunks med 50-ord overlap
- Ignorerer CHUNK_SIZE parameter
- Ingen titel prefiks
- Bedst til: Lange dokumenter med kontekst behov

### Embedding Providers

#### Ollama (Lokale Embeddings)
```bash
# Fordele
+ Ingen API omkostninger
+ Data forbliver lokalt
+ God performance
+ Offline kapabilitet

# Ulemper
- Kr√¶ver mere RAM (8GB+)
- L√¶ngere opstartstid
- Mindre embedding space
```

#### OpenAI (Cloud Embeddings)
```bash
# Fordele
+ H√∏j embedding kvalitet
+ Stor embedding space
+ Hurtig opstart
+ Ingen local resource krav

# Ulemper
- API omkostninger
- Kr√¶ver internet forbindelse
- Data sendes til OpenAI
```

## üìÅ **Filstruktur og Output**

### Input Filer
```
src/
‚îú‚îÄ‚îÄ mine_boeger.txt          # Din bog liste
‚îú‚îÄ‚îÄ .env                     # Konfiguration
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ process_books.sh     # Hovedscript
```

### Output Struktur
```
output/
‚îú‚îÄ‚îÄ processing_status.json   # Real-time status
‚îú‚îÄ‚îÄ processed_books.log     # Detaljeret log
‚îî‚îÄ‚îÄ completion_report.txt   # Afslutningsrapport

failed/
‚îú‚îÄ‚îÄ failed_books.json       # Fejlede b√∏ger til retry
‚îî‚îÄ‚îÄ error_details.log      # Fejl detaljer
```

## ÔøΩ **Konfiguration Troubleshooting**

### Port Konfigurationsproblemer

**Symptom:** `OSError: Multiple exceptions: [Errno 111] Connect call failed ('::1', 5432, 0, 0)`

**√Örsag:** Mismatch mellem den port PostgreSQL k√∏rer p√• og den port aplikationen pr√∏ver at forbinde til.

**Diagnose:**
```bash
# Tjek hvilken port PostgreSQL faktisk k√∏rer p√•
pg_isready -h localhost -p 5432   # Standard port
pg_isready -h localhost -p 5433   # Alternativ port

# Tjek din .env konfiguration
grep POSTGRES_PORT .env

# Tjek Docker port mapping
docker ps | grep postgres
```

**L√∏sning:**

1. **Verific√©r .env fil indeholder korrekt port:**
   ```bash
   # S√∏rg for denne linje er i din .env fil
   POSTGRES_PORT=5433  # Eller hvilken port din database bruger
   ```

2. **Opdat√©r Docker Compose for container networking:**
   ```bash
   # I soegemaskine/docker-compose.yml under book-processor service:
   environment:
     - POSTGRES_HOST=postgres
     - POSTGRES_PORT=5432  # Containers bruger port 5432 internt
   ```

3. **Genstart processing efter √¶ndringer:**
   ```bash
   cd soegemaskine
   docker-compose down
   docker-compose build book-processor  # N√∏dvendigt efter kode√¶ndringer
   docker-compose --profile embeddings up -d
   ./scripts/process_books.sh --validate
   ```

4. **Alternativt: Start PostgreSQL p√• standard port:**
   ```bash
   # √Ündr docker-compose.yml til at bruge standard port
   ports:
     - "5432:5432"  # i stedet for "5433:5432"
   ```

## ÔøΩüêõ **Fejlfinding**

### Almindelige Problemer

#### "File not found" Fejl
```bash
# Problem: Bog liste ikke fundet
# L√∏sning: Tjek fil sti og eksistens
ls -la mine_boeger.txt
./scripts/process_books.sh --file $(pwd)/mine_boeger.txt
```

#### Database Forbindelse Fejl
```bash
# Problem: "Multiple exceptions: [Errno 111] Connect call failed"
# √Örsag: Port mismatch mellem .env og kode

# L√∏sning 1: Verific√©r database k√∏rer p√• korrekt port
pg_isready -h localhost -p 5432  # Standard port
pg_isready -h localhost -p 5433  # Hvis du bruger custom port

# L√∏sning 2: Start database service
cd soegemaskine
docker-compose up -d postgres

# L√∏sning 3: Tjek port konfiguration i .env
grep POSTGRES_PORT .env
# Skal matche den port database faktisk k√∏rer p√•

# Verific√©r database
docker ps | grep postgres
```

#### Embedding Provider Fejl
```bash
# Problem: Ollama ikke tilg√¶ngelig
# L√∏sning: Start Ollama og installer model
cd soegemaskine
docker-compose --profile embeddings up -d ollama
../scripts/setup_ollama.sh

# Problem: OpenAI API fejl
# L√∏sning: Verific√©r API n√∏gle i .env
grep OPENAI_API_KEY .env
```

#### Memory/Performance Problemer
```bash
# Problem: Container killed (OOM)
# L√∏sning: √òg Docker memory limit eller reducer batch st√∏rrelse

# Midlertidig l√∏sning: Reduc√©r CHUNK_SIZE
CHUNK_SIZE=300

# Permanent l√∏sning: √òg Docker memory til 8GB+
```

### Debug Mode
```bash
# K√∏r med detaljeret logging
LOG_LEVEL=DEBUG ./scripts/process_books.sh --file mine_boeger.txt

# Tjek container logs
docker logs soegemaskine-book-processor-1
```

## üìà **Performance Optimering**

### Batch St√∏rrelse
```bash
# For store filer (>10MB hver)
CHUNK_SIZE=300

# For mange sm√• filer
CHUNK_SIZE=600

# Memory-constrained systems
CHUNK_SIZE=200
```

### Concurrent Processing
Systemet bruger automatisk 5 samtidige downloads. For at justere:

```bash
# Redig√©r book_processor_wrapper.py
semaphore = asyncio.Semaphore(3)  # Reduc√©r til 3 for langsommere systemer
```

### Provider Optimering

#### Ollama Performance
```bash
# Forvarm model
docker exec soegemaskine-ollama-1 ollama run nomic-embed-text "test"

# Tjek model status
curl http://localhost:11434/api/tags
```

#### OpenAI Rate Limits
OpenAI har automatisk rate limiting. Ved fejl, vent og pr√∏v igen.

## üìã **Best Practices**

### F√∏r Processering
1. **Valid√©r altid konfiguration** f√∏rst
2. **Test med sm√• bog lister** (1-3 b√∏ger)
3. **Verific√©r database space** for store collections
4. **Backup eksisterende data** hvis relevant

### Under Processering
1. **Overv√•g fremgang** regelm√¶ssigt
2. **Tjek log filer** for warnings
3. **Monitor√©r system ressourcer** (RAM, CPU)
4. **V√¶r t√•lmodig** - store b√∏ger tager tid

### Efter Processering
1. **Gennemg√• fejlede b√∏ger** og find √•rsager
2. **Verific√©r data kvalitet** via s√∏gninger
3. **Backup processed data** for sikkerhed
4. **Dokument√©r processering noter** for teamet

## üîÑ **Batch Processing Workflow**

### Store Samlinger (100+ b√∏ger)
```bash
# 1. Split bog liste i mindre batches
split -l 20 alle_boeger.txt batch_

# 2. Process√©r batch for batch
for batch in batch_*; do
  echo "Processing $batch..."
  ./scripts/process_books.sh --file $batch
  echo "Waiting 5 minutes before next batch..."
  sleep 300
done

# 3. Saml resultater
cat output/processing_status_*.json > samlet_status.json
```

### Kontinuerlig Overv√•gning
```bash
# Background monitoring
while true; do
  ./scripts/process_books.sh --monitor
  sleep 60
done
```

---

**N√¶ste skridt:** Se [Konfigurationsguide](../KONFIGURATION.md) for avancerede indstillinger eller [Lokal Udvikling](LOKAL_UDVIKLING.md) for debugging teknikker.
